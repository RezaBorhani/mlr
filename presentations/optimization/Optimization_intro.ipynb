{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# EECS 395, 495\n",
    "# OPTIMIZATION TECHNIQUES FOR MACHINE LEARNING AND DEEP LEARNING\n",
    "## Jeremy Watt with Reza Borhani\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# About us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  <p>\n",
    "  <img src= \"../../mlrefined_images/presentation_images/NU_logo.png\" width=\"200px\" height=\"auto\"> \n",
    "  </p>\n",
    "  <p>\n",
    "   &nbsp;&nbsp; - Adjunct Professors in EECS department \n",
    "   <br/>\n",
    "  <br/>\n",
    "   &nbsp;&nbsp; - where we both earned our PhDs\n",
    "  </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  <p>\n",
    "  <img src= \"../../mlrefined_images/presentation_images/mlrefined_logo.png\",  width=\"200px\" height=\"auto\"> \n",
    "  </p>\n",
    "  <p>\n",
    "  &nbsp;&nbsp; - Authors of Machine Learning Refined (Cambridge University Press) - www.mlrefined.com\n",
    "  <br/>\n",
    "  <br/>\n",
    "  &nbsp;&nbsp; - Used in EECS 396, 496: Machine Learning: Foundations, Applications, and Algorithms\n",
    "  <br/>\n",
    "  <br/>\n",
    "  &nbsp;&nbsp; - Notes from this class based on *new* material for 2nd edition!\n",
    "\n",
    "  </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  <p>\n",
    "  <img src= \"../../mlrefined_images/presentation_images/dg6_logo.png\"  width=\"200px\" height=\"auto\"> \n",
    "  </p>\n",
    "  <p>\n",
    " &nbsp;&nbsp; - Owners of local deep learning consultancy Degree Six - www.dgsix.com\n",
    "  <br/>\n",
    "  <br/>\n",
    " &nbsp;&nbsp; - We help everyone from startups to established businesses develop AI-fueled products and build machine learning / deep learning teams\n",
    "  </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# About the course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Optimization is the workhorse of machine learning / deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Every way we know how to learn fundamentally requires mathematical optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Supervised learning:** parameters must be properly tuned in order to represent data / make accurate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "    - e.g., linear supervised learning, deep neural networks, random forests, kernel methods,..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Unsupervised learning:** parameters must be properly tuned in order to reduce the dimnension of data properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "    - e.g., PCA, K-Means, Recommender Systems,..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Reinforcement Learning:** large state spaces (e.g., for Atari games) require repeated use of supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "    - Deep Q-Learning, Policy-gradient methods,..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What is mathematical optimization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Every machine learning / deep learning learning problem has parameters that must be tuned properly to ensure optimal learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- e.g., two parameters to tune (slope and intercept) in simplest instance of linear regression - we fit a *line* to data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- These parameters are tuned by forming what is called a *cost function* or *loss function*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Proper tuning of weights corresponds geometrically to *minimizing* the cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../../mlrefined_images/math_optimization_images/bigpicture_regression_optimization.png\" width=2000 height=2000/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../../mlrefined_images/math_optimization_images/bigpicture_classification_optimization.png\" width=2000 height=2000/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What is mathematical optimization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **mathematical optimization is the set of tools designed to find such minima**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- the algorithms are *iterative* in nature (few closed form solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- the algorithms are based on fundamental principles from calculus and geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Course topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Course topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1) **Computational calculus part 1**\n",
    "    - mathematical functions, function arithmetic, the computation graph\n",
    "    - derivative rules, numerical differentiation, automatic differentiation \n",
    "    - the first order condition and alternating descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2)  **Optimization and Unsupervised Learning**\n",
    "    - eigenvalues / eigenvectors and the power method\n",
    "    - PCA, random projections, LDA, Recommender Systems\n",
    "    - K-Means, Nonnegative Matrix Factorization, Sparsity, and other clustering methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " 3) **Computational calculus part 2**\n",
    "    - hyperplanes and high dimensional quadratics\n",
    "    - second derivatives and curvature\n",
    "    - Taylor series, higher order derivatives and computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Course topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "4)   **First and second order methods**\n",
    "    - global and random local search\n",
    "    - gradient descent, normalized and unnormalized forms\n",
    "    - steepest descent variations, steplength rules, stochastic methods\n",
    "    - Newton's method, non-convex adjustments, quasi-Newton's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "5)  **Optimization and supervised learning**\n",
    "    - linear supervised methods\n",
    "    - deep neural networks, specialized first order methods (RProp, RMSprop, ADAM, noisy gradient)\n",
    "    - boosted trees and heuristic methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Logistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Logistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- All **slides and notes** will be posted to https://jermwatt.github.io/mlrefined\n",
    "    - pull this repo and keep it up to date "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We may use a Piazza page for **class forum discussion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Office hours:** 12 - 1pm Mon/Wed in Annenberg Hall room G21 (starting second week of class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Assignments:** 5 homeworks (75% of final grade), 1 individual project (25% of final grade)\n",
    "    - All assignments must be completed using Python 3 Jupyter notebooks, turned in on canvas (no hard copy)\n",
    "    - Late homework = 1% off every hour late starting at end of due class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Expert Google-ing skills**\n",
    "    - You understand how to / the value of Google and Stack overflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Basic familiarity with Linear Algebra and Calculus**\n",
    "    - We **will** review, so OK if rusty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Basic familiarity with fundamental machine learning concepts**\n",
    "    - We **will** review as we go along, so OK if rusty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Strong familiarity with the Python programming language**\n",
    "    - functions / classes (i.e,. basic familiarity with object oriented programming)\n",
    "    - We **will not** review, play catch-up: e.g., https://www.codecademy.com/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Familiarity with using Jupyter notebook enviro for prototyping**\n",
    "    - If unfamiliar easy to catch-up: see e.g., https://www.youtube.com/watch?v=HW29067qVWk&t=639s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Familiarity with github**\n",
    "    - if unfamiliar, make yourself an account and easy catch-up: see e.g., https://www.youtube.com/watch?v=SWYqp7iY_Tc"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
